## CI/CD Security: Using Checkov to Enforce Best Practices

![devsecops-on-steroids](images/checkov-ci/0.png)

[This tutorial on my blog](https://igorzhivilo.com/2025/02/13/checkov-ci/)

The purpose of this tutorial is to provide a solid starting point for enforcing security best practices in your Terraform scripts.

I will walk you through the following steps:
* Integrating Checkov into your gitlab pipeline.
* Enabling specific individual security checks.
* Configuring enforcement to fail the pipeline on failed checks.
* Gradually expanding policy recommendations.

### ðŸš€ Why Use Checkov?

* Prevents security misconfigurations early
* Automates compliance enforcement
* Integrates seamlessly into DevOps pipelines
* Covers multiple IaC frameworks
* Open-source and actively maintained

### Why I Use Checkov

#### Reason 1: Enforce Security
We use Terraform as our Infrastructure as Code (IaC) solution, and we want to enforce security best practices for any Terraform code merged into our repository. Checkov helps us achieve this by providing automated security and compliance checks.

For example, I want to ensure that:
* Every S3 bucket added via Terraform is encrypted to protect sensitive data.
* Every S3 bucket is not publicly accessible to prevent unintended exposure.

By integrating Checkov into our GitLab pipeline, we can automatically scan our Terraform code and enforce these security policies before changes are merged.

#### Reason 2: Compliance
To achieve SOC 2 compliance, your Terraform code must be covered by automated tests. Otherwise, you would need to manually verify and document that each merged commit was tested in a QA environment, which is time-consuming, burdensome, and prone to errors. Automated security testing simplifies this process, ensuring compliance with minimal effort.

## Let's do it!

### Integrate checkov to your pipeline and enabling specific individual security checks.


```yaml
stages:
  - test

static-test:
  stage: test
  allow_failure: true
  image:
    name: bridgecrew/checkov:latest
    entrypoint:
      - '/usr/bin/env'
      - 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'
  script:
    - checkov -d terraform --check CKV_AWS_19,CKV_AWS_20 | tee checkov.test.xml
  artifacts:
    reports:
      junit: "checkov.test.xml"
    paths:
      - "checkov.test.xml"
```


#### Explanation

* A test stage will be added as part of the pipeline.
* the bridgecrew/checkov:latest Docker image will be used, as it comes with Checkov pre-installed. If you prefer not to use this image, you can manually install Checkov using pip:
```yaml
before_script:
  - pip install checkov
```
* All TF code located in terraform directory
* A JUnit report will be generated and attached to each pipeline run for better visibility of the test results.
* In my example, I used two security policies related to S3 bucket security: CKV_AWS_19 and CKV_AWS_20 (--check flag means, allow only the two specified checks to run ).

    * CKV_AWS_19: Ensures that server-side encryption is enabled for the S3 bucket.

    * CKV_AWS_20: Ensures that the S3 bucket is not publicly accessible.

This serves as a great starting point, and you can gradually expand by adding more security policies over time.


### Configuring enforcement to fail the pipeline on failed checks.

1. Go to: Setting -> 'merge requests'

![devsecops-on-steroids](images/checkov-ci/1.png)


2. Enable 'Pipelines must succeed' checkbox and click save

![devsecops-on-steroids](images/checkov-ci/2.png)


### Gradually Expanding Policy Recommendations

> Note: Since we primarily work with AWS, we will focus on AWS-specific policies.

1ï¸âƒ£ Choose an Initial Resource
	â€¢	Start with a single resource, such as an S3 bucket (as in this example).

2ï¸âƒ£ Apply a Minimal Set of Security Policies
	â€¢	Begin with essential security checks for S3:
	â€¢	CKV_AWS_19: Ensures that server-side encryption is enabled for the S3 bucket.
	â€¢	CKV_AWS_20: Ensures that the S3 bucket is not publicly accessible.

3ï¸âƒ£ Align with Existing Terraform Code & Fix Issues
	â€¢	Review current Terraform configurations and remediate any violations based on policy findings.

4ï¸âƒ£ Incrementally Add More Policies Over Time
	â€¢	Introduce additional policies every quarter, ensuring a gradual and manageable improvement.

ðŸ“Œ Each iteration should expand coverageâ€”start with S3, refine policies, and then extend to other AWS resources as needed. ðŸš€

> Another useful option is to utilize a baseline that ignores already known issues, allowing you to focus on new ones. To achieve this, you can create a baseline using the --create-baseline option and then apply it during each scan with the --baseline BASELINE option.

#### Usinfg checkov config file

You can use a configuration file with Checkov, which can be especially helpful if you have a long list of security checks to manage.

```bash
checkov --config-file path/to/config.yaml
```

config.yaml
```yaml
check:
  - CKV_AWS_19
  - CKV_AWS_20
directory:
  - terraform
```

### Suppressing and skipping policies inside code
https://www.checkov.io/2.Basics/Suppressing%20and%20Skipping%20Policies.html#:~:text=Suppressing%2Fskipping,-Like%20any%20static&text=For%20example%2C%20if%20a%20resource,run%20or%20skip%20certain%20checks

#### Example
> The following comment skips the CKV_AWS_20 check on the resource identified by foo-bucket, where the scan checks if an AWS S3 bucket is private. In the example, the bucket is configured with a public read access; Adding the suppression comment skips the appropriate check instead of the check failing.

```terraform
resource "aws_s3_bucket" "foo-bucket" {
  region        = var.region
    #checkov:skip=CKV_AWS_20:The bucket is a public static content host
  bucket        = local.bucket_name
  force_destroy = true
  acl           = "public-read"
}
```

### AWS Policies to Gradually Incorporate into Your Pipeline
